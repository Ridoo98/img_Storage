{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture6_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uEZzwqZ05P8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Revolutional Neural Networks**\n",
        "&emsp; **-Regression:** output variable takes continuous value  \n",
        "&emsp; **-Classification:** output variable takes class label. Can produce probability of belonging to a particular class\n",
        "&nbsp; \n",
        "\n",
        "Aim of RNNs: Learning Feature Representations  \n",
        "\n",
        "Fully Connected Neural Network--  \n",
        "Input: 2D image  \n",
        "Vector of pixel values  \n",
        "Fully Connected: \n",
        "Connect neuron in hidden layer to all neurons in input layer  \n",
        "No spatial information!  \n",
        "And many, many parameters  \n",
        "&nbsp; \n",
        "\n",
        "Feature Extraction with Convolution  \n",
        "1) Apply a set of weights - a filter - to extract **local features**  \n",
        "2) Use **multiple filters** to extract different features  \n",
        "3) **Spatially share** parameters of each filter  \n",
        "&nbsp; \n",
        "\n",
        "CNNs for Classification  \n",
        "1. Convolution: Apply filters to generate feature maps.\n",
        "2. Non-linearity: Often ReLU.\n",
        "3. Pooling: Downsampling operation on each feature map.  \n",
        "![CNN1](https://raw.githubusercontent.com/Ridoo98/img_Storage/main/Lecture_6S_notes/CNN/CNN1.png)\n",
        "\n",
        "`tf.keras.layer.Conv2D`  \n",
        "`tf.keras.activations`  \n",
        "`tf.keras.layer.MaxPool2D`  \n",
        "\n",
        "Convolutional Layers: Local Connectivity  \n",
        "$\\sum_{i=1}^4{} \\sum_{j=1}^4{w_{ij}x_{i+p,j+q}+b}$ &emsp; for neuron $(p,q)$ in hidden layer  \n",
        "`tf.keras.layers.Conv2D`\n",
        "\n",
        "For a neuron in hidden layer:\n",
        "- Take inputs from patch  \n",
        "- Compute weighted sum  \n",
        "- Apply bias  \n",
        "\n",
        "1) applying a window of weights  \n",
        "2) computing linear combinations  \n",
        "3) activating with non-linear function  \n",
        "&nbsp; \n",
        "\n",
        "### **CNNs: Spatial Arrangement of Output Volume**\n",
        "**Layer Dimensions:** h x w x d  \n",
        "where h and w are spatial dimensions d(depth) = number of filters  \n",
        "**Stride:** Filter step size  \n",
        "**Receptive Field:**  Locations in input image that a node is path connected to  \n",
        "`tf.keras.layers.Conv2D( filters=d, kernel_size=(h,w), strides=s )`\n",
        "![](https://github.com/Ridoo98/img_Storage/blob/main/Lecture_6S_notes/CNN/CNN2.png?raw=true)  \n",
        "\n",
        "![](https://github.com/Ridoo98/img_Storage/blob/main/Lecture_6S_notes/CNN/CNN3.png?raw=true)\n",
        "\n",
        "### **Pooling**\n",
        "1) Reduced dimensionality  \n",
        "2) Spatial invariance  \n",
        "`tf.keras.layers.MaxPool2D( pool_size=(2,2), strides=2 ) #max pool with 2X2 filters and stride 2`  \n",
        "\n",
        "### **CNNs for Classification: **  \n",
        "**Feature Learning**\n",
        "![](https://github.com/Ridoo98/img_Storage/blob/main/Lecture_6S_notes/CNN/CNN4.png?raw=true)\n",
        "\n"
      ],
      "metadata": {
        "id": "9FgWwY_w1DAA"
      }
    }
  ]
}